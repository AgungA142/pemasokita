{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "CTqXn9kkDUcL"
      },
      "outputs": [],
      "source": [
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "import random\n",
        "import shutil\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import csv\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6BnzkZn2DqRt",
        "outputId": "0b8ab552-7c27-4864-d252-619e4c550735"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting roboflow\n",
            "  Downloading roboflow-1.0.9-py3-none-any.whl (56 kB)\n",
            "                                              0.0/56.3 kB ? eta -:--:--\n",
            "     --------------------                   30.7/56.3 kB 640.0 kB/s eta 0:00:01\n",
            "     -------------------------------------- 56.3/56.3 kB 731.6 kB/s eta 0:00:00\n",
            "Collecting certifi==2022.12.7 (from roboflow)\n",
            "  Downloading certifi-2022.12.7-py3-none-any.whl (155 kB)\n",
            "                                              0.0/155.3 kB ? eta -:--:--\n",
            "     ----------                              41.0/155.3 kB 1.9 MB/s eta 0:00:01\n",
            "     ---------------                         61.4/155.3 kB 1.6 MB/s eta 0:00:01\n",
            "     ---------------                         61.4/155.3 kB 1.6 MB/s eta 0:00:01\n",
            "     -------------------                   81.9/155.3 kB 651.6 kB/s eta 0:00:01\n",
            "     ---------------------                 92.2/155.3 kB 435.7 kB/s eta 0:00:01\n",
            "     ---------------------                 92.2/155.3 kB 435.7 kB/s eta 0:00:01\n",
            "     --------------------------           112.6/155.3 kB 385.0 kB/s eta 0:00:01\n",
            "     ------------------------------------ 155.3/155.3 kB 440.8 kB/s eta 0:00:00\n",
            "Collecting chardet==4.0.0 (from roboflow)\n",
            "  Downloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n",
            "                                              0.0/178.7 kB ? eta -:--:--\n",
            "     ------                                  30.7/178.7 kB 1.3 MB/s eta 0:00:01\n",
            "     -----------------------                112.6/178.7 kB 1.6 MB/s eta 0:00:01\n",
            "     ----------------------------------     163.8/178.7 kB 1.4 MB/s eta 0:00:01\n",
            "     -------------------------------------- 178.7/178.7 kB 1.3 MB/s eta 0:00:00\n",
            "Collecting cycler==0.10.0 (from roboflow)\n",
            "  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
            "Collecting idna==2.10 (from roboflow)\n",
            "  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
            "                                              0.0/58.8 kB ? eta -:--:--\n",
            "     -------------------                    30.7/58.8 kB 660.6 kB/s eta 0:00:01\n",
            "     -------------------------------------- 58.8/58.8 kB 783.4 kB/s eta 0:00:00\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\surya\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from roboflow) (1.4.4)\n",
            "Requirement already satisfied: matplotlib in c:\\users\\surya\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from roboflow) (3.6.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\surya\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from roboflow) (1.23.5)\n",
            "Requirement already satisfied: opencv-python>=4.1.2 in c:\\users\\surya\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from roboflow) (4.6.0.66)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in c:\\users\\surya\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from roboflow) (9.3.0)\n",
            "Collecting pyparsing==2.4.7 (from roboflow)\n",
            "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
            "                                              0.0/67.8 kB ? eta -:--:--\n",
            "     ------                                   10.2/67.8 kB ? eta -:--:--\n",
            "     ----------------------------------     61.4/67.8 kB 825.8 kB/s eta 0:00:01\n",
            "     -------------------------------------- 67.8/67.8 kB 738.5 kB/s eta 0:00:00\n",
            "Requirement already satisfied: python-dateutil in c:\\users\\surya\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from roboflow) (2.8.2)\n",
            "Requirement already satisfied: python-dotenv in c:\\users\\surya\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from roboflow) (1.0.0)\n",
            "Requirement already satisfied: requests in c:\\users\\surya\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from roboflow) (2.31.0)\n",
            "Requirement already satisfied: six in c:\\users\\surya\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from roboflow) (1.16.0)\n",
            "Requirement already satisfied: urllib3>=1.26.6 in c:\\users\\surya\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from roboflow) (1.26.16)\n",
            "Collecting wget (from roboflow)\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Collecting tqdm>=4.41.0 (from roboflow)\n",
            "  Downloading tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
            "                                              0.0/77.1 kB ? eta -:--:--\n",
            "     ---------------------------------------- 77.1/77.1 kB 2.2 MB/s eta 0:00:00\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in c:\\users\\surya\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from roboflow) (6.0)\n",
            "Collecting requests-toolbelt (from roboflow)\n",
            "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "                                              0.0/54.5 kB ? eta -:--:--\n",
            "     ---------------------------------------- 54.5/54.5 kB 1.4 MB/s eta 0:00:00\n",
            "Requirement already satisfied: colorama in c:\\users\\surya\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm>=4.41.0->roboflow) (0.4.6)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\surya\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->roboflow) (1.0.6)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\surya\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->roboflow) (4.38.0)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\surya\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->roboflow) (22.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\surya\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->roboflow) (3.1.0)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py): started\n",
            "  Building wheel for wget (setup.py): finished with status 'done'\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9681 sha256=fb87bffa1c015d27a44e0100c110af09241648b836e79f9b9d98ce1594686fe5\n",
            "  Stored in directory: c:\\users\\surya\\appdata\\local\\pip\\cache\\wheels\\40\\b3\\0f\\a40dbd1c6861731779f62cc4babcb234387e11d697df70ee97\n",
            "Successfully built wget\n",
            "Installing collected packages: wget, tqdm, pyparsing, idna, cycler, chardet, certifi, requests-toolbelt, roboflow\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.0.9\n",
            "    Uninstalling pyparsing-3.0.9:\n",
            "      Successfully uninstalled pyparsing-3.0.9\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.4\n",
            "    Uninstalling idna-3.4:\n",
            "      Successfully uninstalled idna-3.4\n",
            "  Attempting uninstall: cycler\n",
            "    Found existing installation: cycler 0.11.0\n",
            "    Uninstalling cycler-0.11.0:\n",
            "      Successfully uninstalled cycler-0.11.0\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2023.5.7\n",
            "    Uninstalling certifi-2023.5.7:\n",
            "      Successfully uninstalled certifi-2023.5.7\n",
            "Successfully installed certifi-2022.12.7 chardet-4.0.0 cycler-0.10.0 idna-2.10 pyparsing-2.4.7 requests-toolbelt-1.0.0 roboflow-1.0.9 tqdm-4.65.0 wget-3.2\n",
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n",
            "Downloading Dataset Version Zip in Good-Bad-Bean-1 to tensorflow: 100% [116579893 / 116579893] bytes\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Extracting Dataset Version Zip to Good-Bad-Bean-1 in tensorflow:: 100%|██████████| 4359/4359 [00:01<00:00, 2224.19it/s]\n"
          ]
        }
      ],
      "source": [
        "!pip install roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"1Ew0Rg3kbVvfDLHUTBGf\")\n",
        "project = rf.workspace(\"yzu\").project(\"good-bad-bean\")\n",
        "dataset = project.version(1).download(\"tensorflow\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "4jGh5XbxETjs"
      },
      "outputs": [],
      "source": [
        "TRAINING_FILE = 'Good-Bad-Bean-1/train/_annotations.csv'\n",
        "\n",
        "VALIDATION_FILE = 'Good-Bad-Bean-1/valid/_annotations.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6eCKq0DHD_N",
        "outputId": "738a2109-cac3-458b-ce44-f6f9371763ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First line (header) looks like this:\n",
            "filename,width,height,class,xmin,ymin,xmax,ymax\n",
            "\n",
            "Each subsequent line (data points) look like this:\n",
            "72a2b8f8-c7ca-4222-b2a1-9b82ac7990f4_45_jpg.rf.d17ad7cb4225bfc8720a0543682e6c22.jpg,416,416,good bean,56,1,341,397\n",
            "\n"
          ]
        }
      ],
      "source": [
        "with open(TRAINING_FILE) as training_file:\n",
        "  line = training_file.readline()\n",
        "  print(f\"First line (header) looks like this:\\n{line}\")\n",
        "  line = training_file.readline()\n",
        "  print(f\"Each subsequent line (data points) look like this:\\n{line}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ohROl4q6K2CH"
      },
      "outputs": [],
      "source": [
        "def parse_data_from_input(filename):\n",
        "    dataframe = pd.read_csv(filename)\n",
        "    label_mapping = {'good bean': 0, 'bad bean': 1}\n",
        "    dataframe['class'] = dataframe['class'].map(label_mapping)\n",
        "\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    for _, row in dataframe.iterrows():\n",
        "        image_filename = row['filename']\n",
        "        image_path = os.path.join(os.path.dirname(filename), image_filename)\n",
        "        image = cv2.imread(image_path)\n",
        "        image = cv2.blur(image, (5, 5), 0)\n",
        "\n",
        "        x_min = row['xmin']\n",
        "        y_min = row['ymin']\n",
        "        x_max = row['xmax']\n",
        "        y_max = row['ymax']\n",
        "\n",
        "        cropped_image = image[y_min:y_max, x_min:x_max]\n",
        "        resized_image = cv2.resize(cropped_image, (224, 224))\n",
        "        reshaped_image = np.expand_dims(resized_image, axis=0)\n",
        "        images.append(reshaped_image)\n",
        "        labels.append(row['class'])\n",
        "\n",
        "    images = np.concatenate(images, axis=0)\n",
        "    labels = np.array(labels)\n",
        "\n",
        "    return images, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7G3um2xMsHqI",
        "outputId": "bb94470b-9324-4b65-dbee-40eccb4b7901"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training images has shape: (3807, 224, 224, 3) and dtype: uint8\n",
            "Training labels has shape: (3807,) and dtype: int32\n",
            "Validation images has shape: (363, 224, 224, 3) and dtype: uint8\n",
            "Validation labels has shape: (363,) and dtype: int32\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Test your function\n",
        "training_images, training_labels = parse_data_from_input(TRAINING_FILE)\n",
        "validation_images, validation_labels = parse_data_from_input(VALIDATION_FILE)\n",
        "\n",
        "print(f\"Training images has shape: {training_images.shape} and dtype: {training_images.dtype}\")\n",
        "print(f\"Training labels has shape: {training_labels.shape} and dtype: {training_labels.dtype}\")\n",
        "print(f\"Validation images has shape: {validation_images.shape} and dtype: {validation_images.dtype}\")\n",
        "print(f\"Validation labels has shape: {validation_labels.shape} and dtype: {validation_labels.dtype}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KznLFde1sVj-",
        "outputId": "cfd1c6b6-35ed-4b9c-fa1d-90d1633e83ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Images of training generator have shape: (32, 224, 224, 3)\n",
            "Labels of training generator have shape: (32,)\n",
            "Images of validation generator have shape: (32, 224, 224, 3)\n",
            "Labels of validation generator have shape: (32,)\n"
          ]
        }
      ],
      "source": [
        "def train_val_generators(training_images, training_labels, validation_images, validation_labels):\n",
        "    \"\"\"\n",
        "    Creates the training and validation data generators\n",
        "\n",
        "    Args:\n",
        "        training_images (array): parsed images from the train CSV file\n",
        "        training_labels (array): parsed labels from the train CSV file\n",
        "        validation_images (array): parsed images from the test CSV file\n",
        "        validation_labels (array): parsed labels from the test CSV file\n",
        "\n",
        "    Returns:\n",
        "        train_generator, validation_generator - tuple containing the generators\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    # Instantiate the ImageDataGenerator class\n",
        "    train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        rotation_range=40,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        fill_mode='nearest'\n",
        "    )\n",
        "\n",
        "    # Pass in the appropriate arguments to the flow method\n",
        "    train_generator = train_datagen.flow(\n",
        "        x=training_images,\n",
        "        y=training_labels,\n",
        "        batch_size=32\n",
        "    )\n",
        "\n",
        "    # Instantiate the ImageDataGenerator class (don't forget to set the rescale argument)\n",
        "    # Remember that validation data should not be augmented\n",
        "    validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "    # Pass in the appropriate arguments to the flow method\n",
        "    validation_generator = validation_datagen.flow(\n",
        "        x=validation_images,\n",
        "        y=validation_labels,\n",
        "        batch_size=32\n",
        "    )\n",
        "\n",
        "    return train_generator, validation_generator\n",
        "\n",
        "train_generator, validation_generator = train_val_generators(training_images, training_labels, validation_images, validation_labels)\n",
        "\n",
        "print(f\"Images of training generator have shape: {train_generator[0][0].shape}\")\n",
        "print(f\"Labels of training generator have shape: {train_generator[0][1].shape}\")\n",
        "print(f\"Images of validation generator have shape: {validation_generator[0][0].shape}\")\n",
        "print(f\"Labels of validation generator have shape: {validation_generator[0][1].shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "B0uobaMzd4P6"
      },
      "outputs": [],
      "source": [
        "def create_model():\n",
        "    # load the InceptionResNetV2 architecture with imagenet weights as base\n",
        "    base_model = tf.keras.applications.InceptionResNetV2(\n",
        "                     include_top=False,\n",
        "                     weights='imagenet',\n",
        "                     input_shape=(224,224,3)\n",
        "                     )\n",
        " \n",
        "    base_model.trainable=False     \n",
        "    # Define the model\n",
        "    model = tf.keras.Sequential([\n",
        "        base_model,  \n",
        "        tf.keras.layers.BatchNormalization(renorm=True),\n",
        "        tf.keras.layers.GlobalAveragePooling2D(),\n",
        "        tf.keras.layers.Dense(512, activation='relu'),\n",
        "        tf.keras.layers.Dense(256, activation='relu'),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        tf.keras.layers.Dense(128, activation='relu'),\n",
        "        tf.keras.layers.Dense(2, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "rCqjM0IGd4P6"
      },
      "outputs": [],
      "source": [
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if(logs.get('accuracy') is not None and logs.get('accuracy') > 0.93):\n",
        "            print(\"\\nReached target accuracy so cancelling training!\")\n",
        "            self.model.stop_training = True\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0bHTePgXnSQ",
        "outputId": "14959bd9-eb27-4863-888d-e79cd07df2dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "119/119 [==============================] - ETA: 0s - loss: 0.6399 - accuracy: 0.7460"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "Can't decrement id ref count (unable to extend file properly)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[17], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m callbacks \u001b[39m=\u001b[39m myCallback()\n\u001b[0;32m     15\u001b[0m \u001b[39m#train the model\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m model\u001b[39m.\u001b[39;49mfit(train_generator,\n\u001b[0;32m     17\u001b[0m           epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m,\n\u001b[0;32m     18\u001b[0m           validation_data\u001b[39m=\u001b[39;49mvalidation_generator,\n\u001b[0;32m     19\u001b[0m           callbacks\u001b[39m=\u001b[39;49m[callbacks,early_stopping, checkpoint, reduce_lr])\n",
            "File \u001b[1;32mc:\\Users\\surya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[1;32mc:\\Users\\surya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\h5py\\_hl\\files.py:586\u001b[0m, in \u001b[0;36mFile.close\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    580\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mid\u001b[39m.\u001b[39mvalid:\n\u001b[0;32m    581\u001b[0m     \u001b[39m# We have to explicitly murder all open objects related to the file\u001b[39;00m\n\u001b[0;32m    582\u001b[0m \n\u001b[0;32m    583\u001b[0m     \u001b[39m# Close file-resident objects first, then the files.\u001b[39;00m\n\u001b[0;32m    584\u001b[0m     \u001b[39m# Otherwise we get errors in MPI mode.\u001b[39;00m\n\u001b[0;32m    585\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mid\u001b[39m.\u001b[39m_close_open_objects(h5f\u001b[39m.\u001b[39mOBJ_LOCAL \u001b[39m|\u001b[39m \u001b[39m~\u001b[39mh5f\u001b[39m.\u001b[39mOBJ_FILE)\n\u001b[1;32m--> 586\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mid\u001b[39m.\u001b[39;49m_close_open_objects(h5f\u001b[39m.\u001b[39;49mOBJ_LOCAL \u001b[39m|\u001b[39;49m h5f\u001b[39m.\u001b[39;49mOBJ_FILE)\n\u001b[0;32m    588\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mid\u001b[39m.\u001b[39mclose()\n\u001b[0;32m    589\u001b[0m     _objects\u001b[39m.\u001b[39mnonlocal_close()\n",
            "File \u001b[1;32mh5py\\_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
            "File \u001b[1;32mh5py\\_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
            "File \u001b[1;32mh5py\\h5f.pyx:360\u001b[0m, in \u001b[0;36mh5py.h5f.FileID._close_open_objects\u001b[1;34m()\u001b[0m\n",
            "\u001b[1;31mRuntimeError\u001b[0m: Can't decrement id ref count (unable to extend file properly)"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "model = create_model()\n",
        "#Early stopping callback\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
        "\n",
        "# Model checkpoint callback\n",
        "checkpoint = ModelCheckpoint('best_model_coba3.h5', monitor='val_loss', save_best_only=True)\n",
        "\n",
        "# Learning rate scheduling callback\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3)\n",
        "\n",
        "#accuracy threshold callback\n",
        "callbacks = myCallback()\n",
        "\n",
        "#train the model\n",
        "model.fit(train_generator,\n",
        "          epochs=100,\n",
        "          validation_data=validation_generator,\n",
        "          callbacks=[callbacks,early_stopping, checkpoint, reduce_lr])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eLOfZ31md4P7",
        "outputId": "6a6c130a-a635-490e-d386-b25a597e4a73"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: crop_classification_model2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: crop_classification_model2\\assets\n"
          ]
        }
      ],
      "source": [
        "# Save the entire model as a SavedModel.\n",
        "model.save('crop_classification_model2')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "S1CXAxWad4P7"
      },
      "outputs": [],
      "source": [
        "#save the model as hdf5 file\n",
        "model.save('crop_classification_model4.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 579
        },
        "id": "PGcip8uGzPzm",
        "outputId": "9eff515b-2b60-42d8-cc96-bf3f9ac98b26"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'google.colab'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\__VivoBook__\\Downloads\\Untitled1.ipynb Cell 11\u001b[0m in \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/__VivoBook__/Downloads/Untitled1.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/__VivoBook__/Downloads/Untitled1.ipynb#X13sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgoogle\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcolab\u001b[39;00m \u001b[39mimport\u001b[39;00m files\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/__VivoBook__/Downloads/Untitled1.ipynb#X13sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreprocessing\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mimage\u001b[39;00m \u001b[39mimport\u001b[39;00m load_img, img_to_array\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/__VivoBook__/Downloads/Untitled1.ipynb#X13sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m uploaded \u001b[39m=\u001b[39m files\u001b[39m.\u001b[39mupload()\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from google.colab import files\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "    # Load and preprocess the image\n",
        "    path = '/content/' + fn\n",
        "    img = load_img(path, target_size=(64, 64))\n",
        "    x = img_to_array(img)\n",
        "    x /= 255.0\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "\n",
        "    # Make predictions\n",
        "    predictions = model.predict(x)\n",
        "    predicted_label = int(round(predictions[0][0]))\n",
        "\n",
        "    # Print the predicted label\n",
        "    if predicted_label == 0:\n",
        "        print(f\"{fn} is a good bean\")\n",
        "    else:\n",
        "        print(f\"{fn} is a bad bean\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
